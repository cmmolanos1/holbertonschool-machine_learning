{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "8693-V1-7_Transfer_Learning_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KxeZs771U_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b0e9f74c-7f69-4a28-f380-2a4dc01fbb21"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow.keras as K\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwVskZOdTGZe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_data(X, Y):\n",
        "    X = K.applications.resnet_v2.preprocess_input(X)\n",
        "    Y = K.utils.to_categorical(Y, 10)\n",
        "\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-vjPZA3Wwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7ca6693d-427b-4362-cbea-6becd95a9b70"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    # Divide the data in Train and Test Datasets\n",
        "    (x_train, y_train),(x_test, y_test) = K.datasets.cifar10.load_data()\n",
        "\n",
        "    x_train, y_train = preprocess_data(x_train, y_train)\n",
        "    x_test, y_test = preprocess_data(x_test, y_test)\n",
        "\n",
        "    original_dim = (32, 32, 3)\n",
        "    target_size = (224, 224)\n",
        "    \n",
        "    model = K.applications.ResNet152V2(include_top=False,\n",
        "                                 weights='imagenet',\n",
        "                                 input_shape=(224, 224, 3))\n",
        "    \n",
        "    model.trainable = False\n",
        "\n",
        "    model_1= K.Sequential()\n",
        "    model_1.add(K.layers.Lambda(lambda image: tf.image.resize(image, target_size))) \n",
        "    model_1.add(model)\n",
        "    model_1.add(K.layers.Flatten())\n",
        "    model_1.add(K.layers.Dense(10,activation='softmax', kernel_initializer='he_normal'))\n",
        "\n",
        "    checkpoint = K.callbacks.ModelCheckpoint(filepath='cifar10.h5',\n",
        "                                             monitor='val_acc',\n",
        "                                             mode='max',\n",
        "                                             verbose=1,\n",
        "                                             save_best_only=True)\n",
        "    \n",
        "    model_1.compile(optimizer=K.optimizers.RMSprop(learning_rate=2e-5),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['acc'])\n",
        "\n",
        "    model_1.fit(x_train, y_train,\n",
        "                validation_data=(x_test, y_test),\n",
        "                batch_size=32,\n",
        "                epochs=200,\n",
        "                verbose=1,\n",
        "                callbacks=[checkpoint])\n",
        "\n",
        "    model_1.save('cifar10.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "234553344/234545216 [==============================] - 18s 0us/step\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.8101 - acc: 0.7487\n",
            "Epoch 00001: val_acc improved from -inf to 0.83580, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 272s 5ms/sample - loss: 0.8102 - acc: 0.7487 - val_loss: 0.7126 - val_acc: 0.8358\n",
            "Epoch 2/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.4553 - acc: 0.8579\n",
            "Epoch 00002: val_acc improved from 0.83580 to 0.85180, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.4553 - acc: 0.8579 - val_loss: 0.6997 - val_acc: 0.8518\n",
            "Epoch 3/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.3401 - acc: 0.8915\n",
            "Epoch 00003: val_acc improved from 0.85180 to 0.85330, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.3401 - acc: 0.8915 - val_loss: 0.7240 - val_acc: 0.8533\n",
            "Epoch 4/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9142\n",
            "Epoch 00004: val_acc improved from 0.85330 to 0.85720, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.2661 - acc: 0.9142 - val_loss: 0.7068 - val_acc: 0.8572\n",
            "Epoch 5/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9290\n",
            "Epoch 00005: val_acc improved from 0.85720 to 0.85730, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.2163 - acc: 0.9291 - val_loss: 0.7307 - val_acc: 0.8573\n",
            "Epoch 6/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9431\n",
            "Epoch 00006: val_acc improved from 0.85730 to 0.85890, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.1754 - acc: 0.9431 - val_loss: 0.7488 - val_acc: 0.8589\n",
            "Epoch 7/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9503\n",
            "Epoch 00007: val_acc did not improve from 0.85890\n",
            "50000/50000 [==============================] - 255s 5ms/sample - loss: 0.1484 - acc: 0.9503 - val_loss: 0.7537 - val_acc: 0.8584\n",
            "Epoch 8/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9575\n",
            "Epoch 00008: val_acc improved from 0.85890 to 0.86610, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 256s 5ms/sample - loss: 0.1294 - acc: 0.9575 - val_loss: 0.7302 - val_acc: 0.8661\n",
            "Epoch 9/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9647\n",
            "Epoch 00009: val_acc improved from 0.86610 to 0.86740, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 257s 5ms/sample - loss: 0.1064 - acc: 0.9647 - val_loss: 0.7603 - val_acc: 0.8674\n",
            "Epoch 10/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9687\n",
            "Epoch 00010: val_acc improved from 0.86740 to 0.86930, saving model to cifar10.h5\n",
            "50000/50000 [==============================] - 258s 5ms/sample - loss: 0.0948 - acc: 0.9687 - val_loss: 0.7795 - val_acc: 0.8693\n",
            "Epoch 11/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9731\n",
            "Epoch 00011: val_acc did not improve from 0.86930\n",
            "50000/50000 [==============================] - 257s 5ms/sample - loss: 0.0820 - acc: 0.9731 - val_loss: 0.8156 - val_acc: 0.8646\n",
            "Epoch 12/200\n",
            "49984/50000 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9766\n",
            "Epoch 00012: val_acc did not improve from 0.86930\n",
            "50000/50000 [==============================] - 257s 5ms/sample - loss: 0.0728 - acc: 0.9766 - val_loss: 0.8448 - val_acc: 0.8655\n",
            "Epoch 13/200\n",
            "32960/50000 [==================>...........] - ETA: 1:13 - loss: 0.0600 - acc: 0.9801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5ef8aa7531eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 callbacks=[checkpoint])\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cifar10.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34B2tQE0VCp2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "a8df5104-5bc6-4b42-d033-4f6593a39239"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    }
  ]
}