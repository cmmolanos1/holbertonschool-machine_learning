{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN-sigmpid-tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KxeZs771U_m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84bd3f74-c505-421c-bdad-712c2cde7ed8"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4tmHLdq2MGw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(nx, classes):\n",
        "    \"\"\"Create 2 placeholders.\n",
        "\n",
        "    Args:\n",
        "        nx (int): the number of feature columns in our data.\n",
        "        classes (int): number of classes in classifier.\n",
        "\n",
        "    Returns:\n",
        "\n",
        "    \"\"\"\n",
        "    x = tf.placeholder(tf.float32, shape=[None, nx], name=\"x\")\n",
        "    y = tf.placeholder(tf.float32, shape=[None, classes], name=\"y\")\n",
        "\n",
        "    return x, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDc4yGou2YyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_layer(prev, n, activation):\n",
        "    \"\"\" Create a NN layer.\n",
        "\n",
        "    Args:\n",
        "        prev (tensor): tensor output of the previous layer.\n",
        "        n (int): number of nodes in the layer to create.\n",
        "        activation (tf.nn.activation): activation function.\n",
        "\n",
        "    Returns:\n",
        "        tensor: the layer created with shape [?, n].\n",
        "\n",
        "    \"\"\"\n",
        "    init = tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")\n",
        "    layer = tf.layers.Dense(units=n,\n",
        "                            activation=activation,\n",
        "                            # Weights\n",
        "                            kernel_initializer=init,\n",
        "                            name=\"layer\")\n",
        "\n",
        "    return layer(prev)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILZ6iwZF2hEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_prop(x, layer_sizes=[], activations=[]):\n",
        "    \"\"\"Creates the forward propagation graph for the neural network.\n",
        "    Args:\n",
        "        x (tensor): placeholder for the input data.\n",
        "        layer_sizes (list): list containing the number of nodes in each layer\n",
        "                            of the network.\n",
        "        activations (list): list containing the activation functions for each\n",
        "                            layer of the network.\n",
        "    Returns:\n",
        "        tensor: prediction of neural network.\n",
        "    \"\"\"\n",
        "    A = create_layer(x, layer_sizes[0], activations[0])\n",
        "    for layer in range(1, len(layer_sizes)):\n",
        "        A = create_layer(A, layer_sizes[layer], activations[layer])\n",
        "    return A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEA5PPMV2lYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_accuracy(y, y_pred):\n",
        "    \"\"\"Calculates the accuracy of a prediction\n",
        "\n",
        "    Args:\n",
        "        y (tensor): placeholder for the labels of the input data.\n",
        "        y_pred (tensor): network’s predictions.\n",
        "\n",
        "       Returns:\n",
        "           tensor: the decimal accuracy of the prediction.\n",
        "\n",
        "    \"\"\"\n",
        "    # We need to select the highest probability from the tensor that's\n",
        "    # returned out of the softmax. One we have that, we compare it\n",
        "    # against the actual value of y that we have should expected.\n",
        "    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_pred, 1))\n",
        "\n",
        "    # Calculates and return the accuracy.\n",
        "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKUdzyBs2rUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_loss(y, y_pred):\n",
        "    \"\"\"Calculates the softmax cross-entropy loss of a prediction.\n",
        "\n",
        "    Args:\n",
        "        y (tensor): placeholder for the labels of the input data.\n",
        "        y_pred (tensor): the network’s predictions.\n",
        "\n",
        "    Returns:\n",
        "        tensor: the loss of the prediction\n",
        "    \"\"\"\n",
        "    return tf.losses.softmax_cross_entropy(y, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6huJ9OB22Mi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_train_op(loss, alpha):\n",
        "    \"\"\"Creates the training operation for the network:\n",
        "\n",
        "    Args:\n",
        "        loss (tensor): the loss of the network’s prediction.\n",
        "        alpha: learning rate.\n",
        "\n",
        "    Returns:\n",
        "        an operation that trains the network using gradient descent.\n",
        "    \"\"\"\n",
        "    optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
        "    return optimizer.minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K7bZSqM28Oz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(X_train, Y_train, X_valid, Y_valid, layer_sizes, activations,\n",
        "          alpha, iterations, save_path=\"/tmp/model.ckpt\"):\n",
        "    \"\"\"Builds, trains, and saves a neural network classifier.\n",
        "\n",
        "    Args:\n",
        "        X_train (np.array): training input data.\n",
        "        Y_train (np.array): training labels.\n",
        "        X_valid (np.array): validation input data.\n",
        "        Y_valid (np.array): validation labels.\n",
        "        layer_sizes (list): list containing the number of nodes in each\n",
        "                            layer of the network.\n",
        "        activations (list): list containing the activation functions for each\n",
        "                            layer of the network.\n",
        "        alpha (float): learning rate.\n",
        "        iterations (int): number of iterations to train over.\n",
        "        save_path (str): where to save the model\n",
        "\n",
        "    Returns:\n",
        "        str: the path where the model was saved\n",
        "    \"\"\"\n",
        "    m, nx = X_train.shape\n",
        "    ny = Y_train.shape[1]\n",
        "\n",
        "    x, y = create_placeholders(nx, ny)\n",
        "    tf.add_to_collection('x', x)\n",
        "    tf.add_to_collection('y', y)\n",
        "\n",
        "    y_pred = forward_prop(x, layer_sizes, activations)\n",
        "    tf.add_to_collection('y_pred', y_pred)\n",
        "\n",
        "    accuracy = calculate_accuracy(y, y_pred)\n",
        "    tf.add_to_collection('accuracy', accuracy)\n",
        "\n",
        "    loss = calculate_loss(y, y_pred)\n",
        "    tf.add_to_collection('loss', loss)\n",
        "\n",
        "    optimizer = create_train_op(loss, alpha)\n",
        "    tf.add_to_collection('optimizer', optimizer)\n",
        "\n",
        "    init = tf.global_variables_initializer()\n",
        "    saver = tf.train.Saver()\n",
        "\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for i in range(iterations + 1):\n",
        "\n",
        "            cost_t, accuracy_t = sess.run([loss, accuracy],\n",
        "                                          feed_dict={x: X_train, y: Y_train})\n",
        "            cost_v, accuracy_v = sess.run([loss, accuracy],\n",
        "                                          feed_dict={x: X_valid, y: Y_valid})\n",
        "\n",
        "            if i % 100 == 0 or i == iterations:\n",
        "                print(\"After {} iterations:\".format(i))\n",
        "                print(\"\\tTraining Cost: {}\".format(cost_t))\n",
        "                print(\"\\tTraining Accuracy: {}\".format(accuracy_t))\n",
        "                print(\"\\tValidation Cost: {}\".format(cost_v))\n",
        "                print(\"\\tValidation Accuracy: {}\".format(accuracy_v))\n",
        "\n",
        "            if i < iterations:\n",
        "                sess.run(optimizer, feed_dict={x: X_train, y: Y_train})\n",
        "\n",
        "        path = saver.save(sess, save_path)\n",
        "    return path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GayUtQW3QbT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot(Y, classes):\n",
        "    \"\"\"convert an array to a one-hot matrix\"\"\"\n",
        "    one_hot = np.zeros((Y.shape[0], classes))\n",
        "    one_hot[np.arange(Y.shape[0]), Y] = 1\n",
        "    return one_hot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-vjPZA3Wwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5bee038-55f9-4141-dd4f-e5ed44a9a15b"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "\n",
        "    DATA_URL = 'https://s3.amazonaws.com/intranet-projects-files/holbertonschool-ml/MNIST.npz'\n",
        "    path = tf.keras.utils.get_file('mnist.npz', DATA_URL)\n",
        "    lib= np.load(path)\n",
        "\n",
        "\n",
        "    X_train_3D = lib['X_train']\n",
        "    Y_train = lib['Y_train']\n",
        "    X_train = X_train_3D.reshape((X_train_3D.shape[0], -1))\n",
        "    Y_train_oh = one_hot(Y_train, 10)\n",
        "    X_valid_3D = lib['X_valid']\n",
        "    Y_valid = lib['Y_valid']\n",
        "    X_valid = X_valid_3D.reshape((X_valid_3D.shape[0], -1))\n",
        "    Y_valid_oh = one_hot(Y_valid, 10)\n",
        "\n",
        "    layer_sizes = [256, 256, 10]\n",
        "    activations = [tf.nn.tanh, tf.nn.tanh, None]\n",
        "    alpha = 0.01\n",
        "    iterations = 1000\n",
        "\n",
        "    tf.set_random_seed(0)\n",
        "    save_path = train(X_train, Y_train_oh, X_valid, Y_valid_oh, layer_sizes,\n",
        "                      activations, alpha, iterations, save_path=\"./model.ckpt\")\n",
        "\n",
        "    print(\"Model saved in path: {}\".format(save_path))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/intranet-projects-files/holbertonschool-ml/MNIST.npz\n",
            "17072128/17069880 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "After 0 iterations:\n",
            "\tTraining Cost: 2.8232288360595703\n",
            "\tTraining Accuracy: 0.08726000040769577\n",
            "\tValidation Cost: 2.810532331466675\n",
            "\tValidation Accuracy: 0.08640000224113464\n",
            "After 100 iterations:\n",
            "\tTraining Cost: 0.839337944984436\n",
            "\tTraining Accuracy: 0.7824000120162964\n",
            "\tValidation Cost: 0.7826030850410461\n",
            "\tValidation Accuracy: 0.8061000108718872\n",
            "After 200 iterations:\n",
            "\tTraining Cost: 0.6094845533370972\n",
            "\tTraining Accuracy: 0.8396000266075134\n",
            "\tValidation Cost: 0.5562412142753601\n",
            "\tValidation Accuracy: 0.8597999811172485\n",
            "After 300 iterations:\n",
            "\tTraining Cost: 0.5179605484008789\n",
            "\tTraining Accuracy: 0.8600199818611145\n",
            "\tValidation Cost: 0.4691149890422821\n",
            "\tValidation Accuracy: 0.8770999908447266\n",
            "After 400 iterations:\n",
            "\tTraining Cost: 0.46682360768318176\n",
            "\tTraining Accuracy: 0.8718199729919434\n",
            "\tValidation Cost: 0.4217328131198883\n",
            "\tValidation Accuracy: 0.8866999745368958\n",
            "After 500 iterations:\n",
            "\tTraining Cost: 0.43330156803131104\n",
            "\tTraining Accuracy: 0.8805000185966492\n",
            "\tValidation Cost: 0.3913689851760864\n",
            "\tValidation Accuracy: 0.8925999999046326\n",
            "After 600 iterations:\n",
            "\tTraining Cost: 0.4091453552246094\n",
            "\tTraining Accuracy: 0.8864200115203857\n",
            "\tValidation Cost: 0.3699030876159668\n",
            "\tValidation Accuracy: 0.8970000147819519\n",
            "After 700 iterations:\n",
            "\tTraining Cost: 0.39061272144317627\n",
            "\tTraining Accuracy: 0.8910199999809265\n",
            "\tValidation Cost: 0.35369542241096497\n",
            "\tValidation Accuracy: 0.9018999934196472\n",
            "After 800 iterations:\n",
            "\tTraining Cost: 0.3757499158382416\n",
            "\tTraining Accuracy: 0.8943799734115601\n",
            "\tValidation Cost: 0.34086766839027405\n",
            "\tValidation Accuracy: 0.9045000076293945\n",
            "After 900 iterations:\n",
            "\tTraining Cost: 0.36343157291412354\n",
            "\tTraining Accuracy: 0.8974800109863281\n",
            "\tValidation Cost: 0.33035069704055786\n",
            "\tValidation Accuracy: 0.9070000052452087\n",
            "After 1000 iterations:\n",
            "\tTraining Cost: 0.352960467338562\n",
            "\tTraining Accuracy: 0.9004999995231628\n",
            "\tValidation Cost: 0.32148978114128113\n",
            "\tValidation Accuracy: 0.909600019454956\n",
            "Model saved in path: ./model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}